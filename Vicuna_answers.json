{
    "1": "\nTo join the NERSC Users Group (NUG) Slack workspace, you need to follow these steps:\n\n1. Visit the NERSC Users Group website at <https://www.nersc.gov/users/NUG/>\n2. Click on the \"Join the Slack workspace\" button.\n3. You will be redirected to the NUG Slack workspace registration page.\n4. Fill out the required information, including your name, email address, and affiliation.\n5. Click on the \"Join\" button to complete the registration process.\n\nOnce you have registered and been approved, you will receive an invitation to join the NUG Slack workspace. You can then join the workspace by following the instructions provided in the invitation.\n\nNote that you may need to have a NERSC account to join the NUG Slack workspace. If you don't have a NERSC account yet, you can create one by following the instructions on the NERSC website.\n\n\n\nReferences:\n * <https://www.nersc.gov/users/NUG/>",
    "2": "\nTo open support tickets and make resource requests, NERSC users can visit the [NERSC Help Portal](https://help.nersc.gov). This portal is the preferred method for contacting NERSC and provides a range of support options, including ticket submission, resource requests, and account management.\n\nBefore opening a ticket, users are encouraged to search the [NERSC documentation](https://docs.nersc.gov) and the [NERSC User Group Slack](https://www.nersc.gov/users/NUG/nersc-users-slack/) for potential solutions to their issues. Additionally, users can consult the [NERSC Getting Started Guide](https://docs.nersc.gov//global/cfs/cdirs/nstaff/chatbot/production_code/data/nersc_doc/docs/getting-started/) and other relevant resources to familiarize themselves with NERSC services and best practices.\n\nFor account changes and resource allocation, users can also utilize the [Iris system](https://iris.nersc.gov) (refer to the [Iris guide for users](https://docs.nersc.gov//global/cfs/cdirs/nstaff/chatbot/production_code/data/nersc_doc/docs/iris/iris-for-users/)).\n\nReferences:\n * <https://docs.nersc.gov/getting-started/#help-desk>\n * <https://docs.nersc.gov//global/cfs/cdirs/nstaff/chatbot/production_code/data/nersc_doc/docs/iris/iris-for-users/>\n * <https://help.nersc.gov>",
    "3": "\nIf you want to run a short job on a GPU, you should use the \"standard\" Perlmutter GPU QOS. This QOS is suitable for jobs that require a reasonable amount of GPU resources and have a relatively short execution time. To request resources from this QOS, you can use the following command:\n```bash\nsalloc --nodes 1 --qos gpu --time 00:10:00 -C gpu -A your_account\n```\nReplace `your_account` with the appropriate account name. This command requests a single GPU node for 10 minutes. You can adjust the execution time (`--time`) according to your needs.\n\nPlease note that if you have a preemptible job (i.e., it requests less than 2 hours of walltime), you should use the \"preempt\" QOS. However, if your job requires more than 2 hours of walltime, you should use the \"standard\" or \"high-memory\" QOS, depending on your specific needs.\n\nFor more information on available QOS and their specific characteristics, you can refer to the [NERSC Jobs Policy documentation](https://docs.nersc.gov/jobs/policy/).\n\nReferences:\n * <https://docs.nersc.gov/>\n * <https://www.nersc.gov/users/getting-help/online-help-desk/>",
    "4": "\nMandatory flags for a Slurm job are those that are required to submit and manage the job. These flags are essential for the job to run and receive resources from the Slurm cluster.\n\nThe mandatory flags for a Slurm job are:\n\n1. `sbatch`: This is the command used to submit a job to Slurm. It is the primary flag required to initiate the job submission process.\n2. `--job-name`: This flag specifies the name of the job. It is mandatory to provide a unique job name for each job submission.\n3. `--partition`: This flag specifies the partition where the job will run. It is mandatory to select a partition that is appropriate for the job's requirements.\n4. `--gres`: This flag specifies any generic resources (e.g., GPUs) that the job requires. It is mandatory to request the necessary resources for the job to function correctly.\n\nOptional flags for a Slurm job are those that are not required but can be used to customize the job submission process or manage the job's behavior within the Slurm cluster. These flags can be used to specify additional requirements or preferences for the job.\n\nSome examples of optional flags for a Slurm job are:\n\n1. `--time`: This flag specifies the maximum time a job can run. It is optional but can be used to set a time limit for the job.\n2. `--mem`: This flag specifies the maximum memory a job can use. It is optional but can be used to set a memory limit for the job.\n3. `--cpus-per-task`: This flag specifies the number of CPUs a job can use per task. It is optional but can be used to set a CPU limit for the job.\n4. `--requeue`: This flag specifies whether the job should be requeued if it fails. It is optional but can be used to set a requeue policy for the job.\n5. `--dependency`: This flag specifies dependencies between jobs. It is optional but can be used to define dependencies between jobs in the submission script.\n\nThese are just a few examples of optional flags that can be used in a Slurm job submission. The specific flags used will depend on the requirements of the job and the available options in the Slurm configuration.\n\nReferences:\n * <https://docs.nersc.gov/>\n * <https://www.nersc.gov/users/getting-help/online-help-desk/>",
    "5": "The High Performance Storage System (HPSS) is a modern, flexible, performance-oriented mass storage system used at NERSC for archival storage since 1998. It is intended for long-term storage of data that is not frequently accessed. HPSS employs Hierarchical Storage Management (HSM) software, which allows it to ingest data onto a high-performance disk cache and automatically migrate it to a very large enterprise tape subsystem for long-term retention. The disk cache is designed to retain many days' worth of new data, while the tape subsystem provides cost-effective, scalable long-term data storage. HPSS is particularly useful for data stewardship and preservation, as well as supporting some data sharing needs.\n\n\n\nReferences:\n * <https://docs.nersc.gov/help/acronyms/#acronyms>\n * <https://docs.nersc.gov//global/cfs/cdirs/nstaff/chatbot/production_code/data/nersc_doc/docs/filesystems/archive/>\n * <https://docs.nersc.gov/filesystems/archive/#introduction>",
    "6": "\nTo find the location of the `gcc` executable in your file path, you can use the `which` command in the terminal. Open a terminal and type:\n```bash\nwhich gcc\n```\nThis will display the path to the `gcc` executable, for example:\n```bash\n/usr/bin/gcc\n```\nAlternatively, you can use the `find` command to search for the `gcc` executable in your file system. Open a terminal and type:\n```bash\nfind / -name gcc\n```\nThis will search for the `gcc` executable in the entire file system and display its path if it is found.\n\nReferences:\n * <https://docs.nersc.gov/>\n * <https://www.nersc.gov/users/getting-help/online-help-desk/>",
    "7": "\nTo use sshproxy, you need to install the sshproxy client script on your local machine. You can download the script using the scp command or by downloading the Windows executable from the NERSC website. Once you have the client script, you can run it from the command line to obtain an ssh key that is valid for a limited time (default is 24 hours).\n\nHere are the steps to use sshproxy:\n\n1. Ensure that your NERSC username is the same as your local username. If not, you can specify your NERSC username with the `-u` option when running the sshproxy client script.\n2. Run the sshproxy client script from the command line on a Unix-like computer. The script will prompt you to enter your password and OTP, in the same manner as you would do to ssh to a NERSC system with MFA.\n3. Upon successfully authenticating, the client will install an ssh key and display a message showing the path to the key pair installed on your local computer and the expiration date and time for the keys.\n4. You can now use the generated ssh key to ssh to NERSC systems without further authentication until the key expires.\n\nNote that the sshproxy client script has several command-line options to override its default behavior. You can run `sshproxy.sh -h` to get a help message. Also, if you would like to have a different name for the PPK file, you can use the `-o` option to specify the output filename.\n\nReferences:\n * <https://docs.nersc.gov/connect/mfa/#using-sshproxy>\n * <https://docs.nersc.gov/connect/mfa/#installing-the-client>\n * <https://docs.nersc.gov/connect/mfa/#sshproxy-command-line-options>\n * <https://docs.nersc.gov/connect/mfa/#sshproxy>",
    "8": "\nAs a NERSC user, you are automatically subscribed to the NERSC users email list, which is essential for receiving important information related to NERSC systems and services. However, if you wish to unsubscribe from the NERSC users email list, you can follow these steps:\n\n1. Go to the NERSC New Account Request page by clicking on the following link: <https://iris.nersc.gov/add-user>\n2. Click on the \"I have a current NERSC account\" button.\n3. Enter your existing username in the provided text box.\n4. Search for the project by entering the PI's name or the Project Name in the text box.\n5. Once you find the project, click on the \"Request Access\" button.\n6. In the dialog box that appears, select the \"Unsubscribe from NERSC Users List\" option.\n7. Click on the \"Save Changes\" button to confirm your request.\n\nPlease note that unsubscribing from the NERSC users email list will remove you from all NERSC-related email communications. If you have any questions or concerns about unsubscribing, you can contact the NERSC Helpdesk for assistance.\n\nReferences:\n * <https://docs.nersc.gov/>\n * <https://www.nersc.gov/users/getting-help/online-help-desk/>",
    "9": "\nTo connect to Perlmutter, you will first need to establish a user account and configure Multi-Factor Authentication (MFA) on the NERSC systems. Once you have done that, you can use the following steps to log in:\n\n1. Open a terminal or command prompt on your local machine.\n2. Use the following command to connect to Perlmutter:\n```\nssh <user>@perlmutter.nersc.gov\n```\nor\n```\nssh <user>@saul.nersc.gov\n```\nIf you have configured sshproxy, you can use the following command:\n```\nssh -i ~/.ssh/nersc <user>@perlmutter.nersc.gov   # or 'ssh -i ~/.ssh/nersc <user>@saul.nersc.gov'\n```\nThis assumes your identity file is in `~/.ssh/nersc`. The sshproxy route will be convenient if you have multiple SSH connections without having to authenticate every time.\n\nAlternatively, you can use the NoMachine NX software to connect to Perlmutter. First, install the NoMachine NX client on your local machine and configure a connection to NERSC. Then, launch the NoMachine client and click the \"Connect to NERSC\" button. Enter your NERSC username and password (and One-Time Password if required) to authenticate and connect to Perlmutter.\n\nFor more detailed instructions on connecting to Perlmutter, you can refer to the NERSC documentation on [connecting to Perlmutter with a collaboration account](https://docs.nersc.gov/connect/#connecting-to-perlmutter-with-a-collaboration-account) and [connecting with SSH](https://docs.nersc.gov/connect/#connecting-with-ssh).\n\n\n\nReferences:\n * <https://docs.nersc.gov/connect/#connect-to-nersc-computational-systems>\n * <https://docs.nersc.gov/connect/#perlmutter>",
    "10": "\nTo install and use a library that currently does not exist on Perlmutter, you can follow these steps:\n\n1. Check if the library is available in the Spack upstreams. If it is, you can install it using Spack. Otherwise, you can build it from source.\n2. If you decide to build the library from source, ensure that you have the necessary dependencies installed. Check the library's documentation or source code to determine the required dependencies.\n3. Install the required dependencies by running the appropriate commands. For example, if you need to install `gcc`, you can use the following command:\n```shell\nmodule load gcc\n```\n4. Clone the library's source code from its repository or download it from a reliable source.\n5. Navigate to the library's directory and configure it for installation using the appropriate commands, depending on the library. This may involve running `configure`, `make`, and `make install`.\n6. Once the library is installed, you can load it using the `module load` command. For example, if you installed the library in the directory `/path/to/library`, you can load it with the following command:\n```shell\nmodule load /path/to/library\n```\n7. After loading the library, you can use it in your code or scripts as needed.\n\nRemember to check the library's documentation for any additional steps or requirements specific to that library.\n\nReferences:\n * <https://docs.nersc.gov/applications/e4s/spack_environments/#spack-upstreams>\n * <https://docs.nersc.gov/development/languages/python/using-python-perlmutter/#cunumeric>",
    "11": "\nTo view your active and previous job statuses on NERSC systems, you can use the `squeue` command. This command allows you to query the status of your jobs in the queue and on the nodes.\n\nTo view all your active jobs, run:\n```\nsqueue -u <username>\n```\nReplace `<username>` with your NERSC username.\n\nTo view all your completed jobs, run:\n```\nsqueue -u <username> -c\n```\nAgain, replace `<username>` with your NERSC username.\n\nThese commands will provide you with information about the job ID, partition, name, user, state, start time, and end time (if applicable) for your active and completed jobs, respectively.\n\nAdditionally, you can use the `sacct` command to retrieve detailed information about your completed jobs, including resource usage, job steps, and more. For example:\n```\nsacct -u <username> -j <job_id>\n```\nReplace `<username>` with your NERSC username and `<job_id>` with the ID of the job you want to query.\n\nThese tools will help you monitor the status and performance of your jobs on NERSC systems.\n\nReferences:\n * <https://docs.nersc.gov/>\n * <https://www.nersc.gov/users/getting-help/online-help-desk/>",
    "12": "\nThe reasons for a job getting killed before finishing can be varied. However, based on the information provided, it seems that the job might be getting killed due to resource contention or time limits.\n\nOne possible reason could be that your job is consuming more resources than expected, and other jobs in the queue are also competing for the same resources. This could lead to resource contention, causing your job to be preempted. You can check the resource usage of your job by looking at the output of the `sacct` command, which shows the CPU and memory usage of your job.\n\nAnother possible reason could be that your job is taking too much time to complete, and it is exceeding the time limit specified in your job script. You can check the time limit specified in your job script by looking at the `time` parameter in the `sbatch` command. You can also check the time remaining for your job by looking at the output of the `sacct` command.\n\nTo troubleshoot the issue further, you can try the following:\n\n1. Check the resource usage of your job by running the `sacct` command and looking at the CPU and memory usage.\n2. Check the time limit specified in your job script by looking at the `time` parameter in the `sbatch` command.\n3. Check the time remaining for your job by looking at the output of the `sacct` command.\n4. Check if there are any errors in your job script or code that could be causing the job to fail.\n5. Try to reduce the resource usage of your job or increase the time limit to avoid resource contention or time limits.\n6. If you are still facing issues, you can contact the NERSC support team for further assistance.\n\nReferences:\n * <https://docs.nersc.gov/>\n * <https://www.nersc.gov/users/getting-help/online-help-desk/>",
    "13": "\nTo cancel all your jobs at once, you can use the `scancel` command with the `-u` option to specify the username associated with the jobs you want to cancel.\n\nFor example, if your username is `jdoe`, you can use the following command to cancel all your jobs:\n```\nscancel -u jdoe\n```\nThis command will send a cancellation signal to all the jobs associated with the specified username, and they will be terminated if possible. Note that some jobs may not be canceled if they are in a state that does not allow cancellation or if they are running on resources that do not support cancellation.\n\nIf you want to cancel specific jobs based on their job IDs, you can use the `scancel` command with the job ID as an argument. For example:\n```\nscancel 12345 67890\n```\nThis command will cancel the jobs with job IDs 12345 and 67890.\n\nKeep in mind that canceling jobs can have consequences, such as losing unsaved work or increasing the likelihood of resource conflicts. Therefore, it is important to use this command carefully and only when necessary.\n\n\n\nReferences:\n * <https://docs.nersc.gov/>\n * <https://www.nersc.gov/users/getting-help/online-help-desk/>",
    "14": "\nTo run a job on a CPU, you can use the NERSC supercomputing center's Perlmutter CPU nodes. These nodes offer a powerful computing environment for running CPU-intensive workloads.\n\nTo submit a job on the Perlmutter CPU nodes, you can use the `sbatch` command followed by the appropriate batch script. The batch script should include the necessary information such as the job name, resource requirements, and execution time.\n\nHere's an example of a batch script for running a job on the Perlmutter CPU nodes:\n```bash\n#!/bin/bash\n#SBATCH -N 1            # Number of tasks to run\n#SBATCH -c 2             # Number of cores per task\n#SBATCH -q regular       # Queue to submit the job to\n#SBATCH -t 01:00:00      # Maximum time limit for the job\n#SBATCH -C cpu           # Resource type (CPU)\n#SBATCH -o %x-%j.out      # Output file prefix\n#SBATCH -e %x-%j.err      # Error file prefix\n\n# Load the necessary modules\nmodule load vasp\n\n# Run the job\nsrun -n 1 -c 2 --cpu-bind=cores vasp_std\n```\nIn this example, the job will run with one task, two cores per task, and a maximum time limit of one hour. The `module load vasp` command loads the necessary module for running the VASP code on the CPU nodes. The `srun` command runs the job with the specified number of tasks, cores, and CPU bindings.\n\nTo submit the job, you can use the `sbatch` command followed by the path to the batch script:\n```shell\nsbatch path/to/batch_script.sh\n```\nMake sure to replace `path/to/batch_script.sh` with the actual path to your batch script.\n\nFor more information on running jobs on the Perlmutter CPU nodes, you can refer to the NERSC documentation on [sample job scripts](https://docs.nersc.gov/applications/vasp/#sample-job-scripts) and [launching programs with Slurm](https://docs.nersc.gov/development/languages/python/parallel-python/#launching-programs).\n\nReferences:\n * <https://docs.nersc.gov/development/languages/python/parallel-python/#launching-programs>\n * <https://docs.nersc.gov/applications/vasp/#sample-job-scripts>",
    "15": "\nYou can ssh into Perlmutter without using a VPN, as long as you have the necessary SSH keys configured on your local machine. To connect to Perlmutter, you can use the following command:\n```css\nssh <username>@perlmutter.nersc.gov\n```\nReplace `<username>` with your NERSC username. If you have configured sshproxy, you can use the following command instead:\n```css\nssh -i ~/.ssh/nersc <username>@perlmutter.nersc.gov\n```\nThis assumes your identity file is in `~/.ssh/nersc`.\n\nNote that if you are not on a NERSC-managed machine, you may need to configure your SSH client to use the correct authentication methods. Additionally, you may need to ensure that your SSH connection is secure and encrypted.\n\n\n\nReferences:\n * <https://docs.nersc.gov/connect/#connecting-with-ssh>\n * <https://docs.nersc.gov/connect/nx/#configure-a-nersc-connection>\n * <https://docs.nersc.gov/connect/mfa/#ssh-configuration-file-options>",
    "16": "\nIf your project runs out of time, you may still be able to run jobs, but they will be restricted to specific queues. According to the NERSC documentation, when a project runs out of time (or space in HPSS), all login names which are not associated with another active project are restricted. Restricted users are able to log in, but cannot submit batch jobs or run parallel jobs, except to the \"overrun\" partition. For HPSS, restricted users are able to read data from HPSS and delete files, but cannot write any data to HPSS. If you have previously run jobs on default queues (`debug`, `regular`), your jobs will be stuck indefinitely and you should consider killing them.\n\nIf your account incurs a negative balance, your project will be restricted to the subset of queues. In this case, you will need to change your job script or specify a different project with sufficient allocation when submitting a job, or run jobs in overrun only.\n\nIt's important to monitor your project's allocation and take necessary actions to avoid running out of time or space. You can check your project's usage and allocation information through the NERSC website or by contacting the NERSC support staff.\n\nReferences:\n * <https://docs.nersc.gov/policies/resource-usage/#running-out-of-allocation>\n * <https://docs.nersc.gov/jobs/troubleshooting/#troubleshooting-jobs>",
    "17": "\nTo write a script to submit a job to Perlmutter, you can follow these steps:\n\n1. Choose the job scheduler:\nPerlmutter supports both Slurm and PBS Pro job schedulers. You can choose the one that suits your needs.\n2. Choose the job scripting language:\nYou can use any scripting language that can interact with the chosen job scheduler. Examples include Bash, Python, and Ruby.\n3. Write the job script:\nYour job script should include the following components:\n\t* Job name and description\n\t* Resource requirements (CPU, memory, GPUs, etc.)\n\t* Executable and input/output files\n\t* Any necessary environment variables or dependencies\n\t* Job scheduling parameters (queue, priority, time limits, etc.)\n\nHere's a simple example of a job script in Bash for submitting a job to Perlmutter using Slurm:\n```bash\n#!/bin/bash\n\n# Job name and description\n#SBATCH --job-name=my_job\n#SBATCH --job-description=\"My job description\"\n\n# Resource requirements\n#SBATCH --cpus-per-task=4\n#SBATCH --mem-per-cpu=2GB\n#SBATCH --time=01:00:00\n\n# Executable and input/output files\n# Replace with your actual executable and input/output files\nexecutable=/path/to/my_executable\ninput_file=/path/to/my_input_file\noutput_file=/path/to/my_output_file\n\n# Environment variables or dependencies\nmodule load my_module\n\n# Job scheduling parameters\n#SBATCH --queue=my_queue\n#SBATCH --priority=medium\n\n# Run the job\nsbatch $executable $input_file > $output_file 2>&1\n```\n1. Submit the job:\nOnce you have written the job script, you can submit it to Perlmutter using the `sbatch` command. Make sure to replace the placeholders in the script with the appropriate values for your job.\n\nFor example, if your job script is named `my_job.sh`, you can submit it with the following command:\n```shell\nnersc$ sbatch my_job.sh\n```\nThis will submit your job to the Perlmutter system, and you can monitor its progress using the Slurm command-line interface or web interface.\n\n\n\nReferences:\n * <https://docs.nersc.gov/jobs/policy/>\n * <https://docs.nersc.gov/tutorials/playbooks/running/#step-4-write-a-batch-script>\n * <https://docs.nersc.gov/services/sfapi/examples/#batch-job-submission>",
    "18": "To set up Multi-Factor Authentication (MFA) for your NERSC account, follow these steps:\n\n1. Ensure that your account has MFA enabled. You can check this by logging into Iris and looking for the MFA token configuration option in your account settings.\n2. If MFA is not enabled, contact the NERSC helpdesk to enable it for your account.\n3. Once MFA is enabled, you will need to create and install an MFA token. You can do this by following the instructions provided by NERSC. Typically, this involves generating a token in the Iris portal and installing it on your authenticator app.\n4. After installing the token, you will need to use it in conjunction with your NERSC password to log into NERSC resources. The specific process for using the token may vary depending on the resource you are trying to access.\n\nIt's important to keep your MFA token secure and not share it with anyone. If you lose your MFA token or it is compromised, you can request a one-time password from NERSC to log into Iris and set up a new token.\n\n\n\nReferences:\n * <https://docs.nersc.gov/connect/mfa/#if-you-lost-your-tokens>\n * <https://docs.nersc.gov/connect/mfa/#configuring-and-using-an-mfa-token>\n * <https://docs.nersc.gov/accounts/passwords/#multi-factor-authentication>",
    "19": "\nThere are several reasons why you might be having trouble logging in to NERSC systems. Here are some troubleshooting steps you can take:\n\n1. Check your username and password: Make sure you are using the correct username and password to log in. If you have recently changed your password, make sure to use the new password.\n2. Check for login failures: If you have been repeatedly entering the wrong password, your login privileges may be disabled. You can check the number of login failures on Iris by selecting the 'Profile' tab and clicking the 'Account Locked?' button. If your account is locked, you can unlock it by clicking the 'Unlock Account' button.\n3. Check for MFA issues: If you have enabled MFA, make sure you are entering the correct one-time password (OTP) when prompted. If you have been entering the wrong OTP repeatedly, you may be locked out of the system. You can wait for 15 minutes and try again.\n4. Check for IP address issues: If you are using a web service in Spin, check if the IP address in the `X-Forwarded-For` HTTP header is correct. You can configure your web service to obtain the IP address from this header.\n5. Check for SSH key issues: If you are using SSH keys for authentication, make sure they have not expired. Also, check if you are using the correct key when prompted.\n6. Check for timeout issues: If you are running `mpi4py` on a large number of nodes, you may experience timeouts or slow performance due to metadata moving across the filesystems. You can try setting the `PMI_MMAP_SYNC_WAIT_TIME` environment variable to increase the timeout limit.\n\nIf none of these troubleshooting steps work, you can contact the NERSC Account Support Office by sending an email to [accounts@nersc.gov](mailto:accounts@nersc.gov) for further assistance.\n\nReferences:\n * <https://docs.nersc.gov/services/spin/faq/#why-are-ip-addresses-in-the-10420016-range-showing-in-my-web-service-access-log>\n * <https://docs.nersc.gov/connect/nx/#troubleshooting-nx-connection-failures>\n * <https://docs.nersc.gov/connect/mfa/#q-i-have-enabled-mfa-my-logins-fail-repeatedly-what-should-i-do>\n * <https://docs.nersc.gov/accounts/passwords/#login-failures>",
    "20": "\nTo determine which file system you should use to store your data, consider the intended use-case and access pattern of your data. NERSC provides different file systems with varying performance, data persistence, and available capacity.\n\n1. Home file system: This file system is intended for individual users and is not recommended for long-term data storage. It offers snapshots and backups but does not persist data beyond the current project.\n2. Common file system: This file system is designed for shared use by multiple projects and offers better data persistence than the Home file system. However, it does not provide snapshots or backups.\n3. Community file system: This file system is optimized for large data sets and long-term storage. It offers snapshots, backups, and better data persistence than the Common file system.\n4. Perlmutter Scratch file system: This file system is the fastest and best suited for large-scale I/O operations. It is designed for temporary storage during job execution and is not intended for long-term data storage.\n5. HPSS file system: This file system is designed for long-term storage of data that is not frequently accessed. It is suitable for archiving data that is not critical for regular job execution.\n\nWhen choosing a file system, consider factors such as the size of your data, the frequency of data access, and the intended lifespan of the data. For example, if you have a large dataset that you access frequently, the Community or Perlmutter Scratch file systems may be more suitable. If you have a smaller dataset that you access infrequently, the HPSS file system may be more appropriate.\n\nIt is essential to note that NERSC storage systems are not designed for disaster-proof data storage. It is recommended to have at least one copy of your data at another institution or cloud service to ensure data availability in case of any issues at NERSC.\n\nReferences:\n * <https://docs.nersc.gov/performance/io/dvs/#read-your-data-from-the-right-place>\n * <https://docs.nersc.gov/filesystems/#summary>"
}